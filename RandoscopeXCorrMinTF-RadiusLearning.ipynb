{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "%load_ext autoreload   \n",
    "%autoreload 2\n",
    "\n",
    "#Autoreloading of modules so you don't have to restart kernel after editing .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from miniscope_utils_tf import *\n",
    "#import utils as krist\n",
    "import scipy.misc as sc\n",
    "from skimage.transform import resize as imresize\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "from IPython import display\n",
    "import scipy.ndimage as ndim\n",
    "import scipy.misc as misc\n",
    "from scipy import signal\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.animation as animation\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import time\n",
    "from itertools import permutations\n",
    "from itertools import combinations\n",
    "#import copy\n",
    "#from bridson import poisson_disc_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = '/gpu:0'\n",
    "#print(tf.test.is_gpu_available())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model and loss\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, ):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.samples = (768,768)   #Grid for PSF simulation\n",
    "\n",
    "        # min and max lenslet focal lengths in mm\n",
    "        self.fmin = 6.\n",
    "        self.fmax = 20.\n",
    "        self.ior = 1.56\n",
    "        self.lam=510e-6\n",
    "        # Min and max lenslet radii\n",
    "        self.Rmin = self.fmin*(self.ior-1.)\n",
    "        self.Rmax = self.fmax*(self.ior-1.)\n",
    "\n",
    "        # Convert to curvatures\n",
    "        self.cmin = 1/self.Rmax\n",
    "        self.cmax = 1/self.Rmin\n",
    "        self.xgrng = np.array((-1.8, 1.8)).astype('float32')    #Range, in mm, of grid of the whole plane (not just grin)\n",
    "        self.ygrng = np.array((-1.8, 1.8)).astype('float32')\n",
    "\n",
    "        self.t = 10.    #Distance to sensor from mask in mm\n",
    "\n",
    "        #Compute depth range of virtual image that mask sees (this is assuming an objective is doing some magnification)\n",
    "\n",
    "        self.zmin_virtual = 1./(1./self.t - 1./self.fmin)\n",
    "        self.zmax_virtual = 1./(1./self.t - 1./self.fmax)\n",
    "        self.CA = .9; #semi clear aperature of GRIN\n",
    "        self.mean_lenslet_CA = .2 #average lenslest semi clear aperture in mm. \n",
    "            \n",
    "        #Getting number of lenslets and z planes needed as well as defocus list\n",
    "        self.ps = (self.xgrng[1] - self.xgrng[0])/self.samples[0]\n",
    "        self.Nlenslets=np.int(np.floor((self.CA**2)/(self.mean_lenslet_CA**2)))\n",
    "        self.Nz = np.ceil(np.sqrt(self.Nlenslets*2)).astype('int') #number of Zplanes \n",
    "        self.defocus_list = 1./(np.linspace(1/self.zmin_virtual, 1./self.zmax_virtual, self.Nz)) #mm or dioptres\n",
    "        self.min_offset= -2e-3\n",
    "        self.max_offset= 2e-3\n",
    "        self.lenslet_offset=tfe.Variable(tf.zeros(self.Nlenslets),name='offset', dtype = tf.float32,constraint=lambda t: tf.clip_by_value(t,self.min_offset, self.max_offset))\n",
    "        #initializing the x and y positions\n",
    "        [xpos,ypos, rlist]=poissonsampling_circular(self)\n",
    "        \n",
    "        self.min_r= self.Rmin\n",
    "        self.max_r= self.Rmax\n",
    "        self.rlist = tfe.Variable(rlist,name='rlist', dtype = tf.float32,constraint=lambda t: tf.clip_by_value(t,self.min_r, self.max_r))\n",
    "        self.xpos = tfe.Variable(xpos, name='xpos', dtype = tf.float32, constraint=lambda t: tf.clip_by_value(t,-self.CA, self.CA))\n",
    "        self.ypos = tfe.Variable(ypos, name='ypos', dtype = tf.float32, constraint=lambda t: tf.clip_by_value(t,-self.CA, self.CA))\n",
    "        \n",
    "        #parameters for making the lenslet surface\n",
    "        self.yg = tf.constant(np.linspace(self.ygrng[0], self.ygrng[1], self.samples[0]),dtype=tf.float32)\n",
    "        self.xg=tf.constant(np.linspace(self.xgrng[0], self.xgrng[1], self.samples[1]),dtype=tf.float32)\n",
    "        self.px=tf.constant(self.xg[1] - self.xg[0],tf.float32)\n",
    "        self.py=tf.constant(self.yg[1] - self.yg[0],tf.float32)\n",
    "        self.xgm, self.ygm = tf.meshgrid(self.xg,self.yg)\n",
    "\n",
    "        #PSF generation parameters\n",
    "        self.lam=tf.constant(510.*10.**(-6.),dtype=tf.float32)\n",
    "        self.k = np.pi*2./self.lam\n",
    "        \n",
    "        fx = tf.constant(np.linspace(-1./(2.*self.ps),1./(2.*self.ps),self.samples[1]),dtype=tf.float32)\n",
    "        fy = tf.constant(np.linspace(-1./(2.*self.ps),1./(2.*self.ps),self.samples[0]),dtype=tf.float32)\n",
    "        self.Fx,self.Fy = tf.meshgrid(fx,fy)\n",
    "        self.field_list = tf.constant(np.array((0., 0.)).astype('float32'))\n",
    "        \n",
    "        self.corr_pad_frac = .5\n",
    "        self.target_res = 12 # micron\n",
    "        sig = self.target_res/2.355 * 1e-3\n",
    "        real_target = tf.exp(-(tf.square(self.xgm) + tf.square(self.ygm))/(2*tf.square(sig)))\n",
    "        real_target = pad_frac_tf(real_target / tf.reduce_max(real_target), self.corr_pad_frac)\n",
    "        self.target_F = tf.abs(tf.fft2d(tf.complex(tf_fftshift(real_target), 0.)))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        T,aper=make_lenslet_tf(self) #offset added\n",
    "        # Get psf stack\n",
    "        zstack = self.gen_psf_stack(T, aper, 0.5)\n",
    "        \n",
    "        psf_spect = self.gen_stack_spectrum(zstack)\n",
    "\n",
    "        normsize=tf.to_float(tf.shape(psf_spect)[0]*tf.shape(psf_spect)[1])\n",
    "        \n",
    "        Rmat_tf=[]\n",
    "        #calculating Xcorr\n",
    "\n",
    "        for z1 in range(self.Nz):\n",
    "            for z2 in range(self.Nz):\n",
    "                Fcorr = tf.conj(psf_spect[z1])*psf_spect[z2]\n",
    "                if z1 == z2:\n",
    "                    # Difference between autocorrelation and target bandwidth\n",
    "                    \n",
    "                    Rmat_tf.append(tf.reduce_sum(tf.square(tf.abs(Fcorr) - self.target_F)))\n",
    "                    \n",
    "                else:\n",
    "                    # Target is zero for cross correlation\n",
    "                    Rmat_tf.append(tf.reduce_sum(tf.square(tf.abs(Fcorr))))  #changed to one norm\n",
    "                \n",
    "                    \n",
    "                    \n",
    "            \n",
    "\n",
    "        #Rmat=tf.reshape(Rmat_tf,(self.Nz,self.Nz))\n",
    "            \n",
    "        return Rmat_tf #note this returns int data type!! vector not matrix. This is also my loss!\n",
    "    \n",
    "    def gen_psf_stack(self, T, aper, prop_pad):\n",
    "        zstack = []\n",
    "        for defocus in self.defocus_list:\n",
    "            zstack.append(gen_psf_ag_tf(T,self,defocus,'angle',0., prop_pad))\n",
    "        return zstack\n",
    "    \n",
    "    def gen_stack_spectrum(self, zstack):\n",
    "                #Padding for fft\n",
    "        psf_pad=[]\n",
    "#         Rmat = np.zeros((self.Nz,self.Nz))\n",
    "\n",
    "        for z1 in range(self.Nz):\n",
    "            psf_pad.append(pad_frac_tf(zstack[z1],self.corr_pad_frac)) #how much to pad? \n",
    "\n",
    "        psf_spect=[]\n",
    "        \n",
    "        #Getting spectrum\n",
    "\n",
    "        for z1 in range(self.Nz):\n",
    "            psf_spect.append(tf.fft2d(tf.complex(tf_fftshift(psf_pad[z1]),tf.constant(0.,dtype = tf.float32))))\n",
    "\n",
    "        return psf_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(model, x,y):\n",
    "    dist = []\n",
    "    dist_bool = []\n",
    "    things = np.arange(model.Nlenslets)\n",
    "    test_perm = list(permutations(things, 2))\n",
    "\n",
    "    for i in range(0, len(test_perm)):\n",
    "        dist_i = tf.sqrt(tf.square(x[test_perm[i][0]]-x[test_perm[i][1]])+tf.square(y[test_perm[i][0]]-y[test_perm[i][1]]))\n",
    "        dist.append(dist_i)\n",
    "        dist_bool.append(dist_i>0*model.mean_lenslet_CA)  ##fix later\n",
    "        \n",
    "    return dist, dist_bool, test_perm\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#with tf.device(\"/gpu:0\"):\n",
    "#    zstack=model(0)\n",
    "#end = time.time()\n",
    "#print(end - start)\n",
    "#with tf.device(\"/cpu:0\"):\n",
    "model = Model()\n",
    "Rmat=model(0)\n",
    "R_init = Rmat\n",
    "Tinit,_=make_lenslet_tf(model)\n",
    "xinit = model.xpos\n",
    "yinit = model.ypos\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Tinit.numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tf.reshape(R_init,(model.Nz,model.Nz)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# T,aper=make_lenslet_tf(model)\n",
    "# test2 = model.gen_psf_stack(T, aper, .5)\n",
    "# test = model.gen_stack_spectrum(test2)\n",
    "# fig = plt.figure()\n",
    "\n",
    "# f,ax = plt.subplots(1,2,figsize=(20,20))\n",
    "\n",
    "# ax[0].imshow(T)\n",
    "\n",
    "\n",
    "# for z in range(model.Nz):\n",
    "# #     ax[1].imshow((tf.real((test[z] * tf.conj(test[z])))) - model.target_F, vmax = 50)\n",
    "#     ax[1].imshow((tf.real((test2[z]))))\n",
    "\n",
    "#     display.display(f)\n",
    "#     display.clear_output(wait=True)\n",
    "\n",
    "# print(tf.reduce_max(test2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have tf do everything for us\n",
    "def loss (model):\n",
    "    return tf.reduce_sum(tf.square(model(0)))\n",
    "\n",
    "def gradient (model, myloss):\n",
    "    with tf.GradientTape() as tape:\n",
    "        lossvalue=myloss(model)\n",
    "        return tape.gradient(lossvalue, model.variables),lossvalue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain_distances(model, new_xpos, new_ypos, grads):\n",
    "    test_dist, test_dist_bool, perm = distances(model, new_xpos, new_ypos)\n",
    "    grads = np.ones((2,model.Nlenslets))\n",
    "    for i in range(0,len(perm)):\n",
    "        if test_dist_bool[i].numpy() == False:\n",
    "            index = perm[i][0]\n",
    "            grads[0,index] = 0\n",
    "            grads[1,index] = 0\n",
    "    return grads, test_dist, test_dist_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_gradients(grads):\n",
    "   # Get rid of NaN gradients\n",
    "   for g in range(0,len(grads)):\n",
    "       if np.any(tf.is_nan(grads[g])):\n",
    "           new_grad = tf.where(tf.is_nan(grads[g]), tf.zeros_like(grads[g]), grads[g])\n",
    "           grads[g] = new_grad\n",
    "   return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_size = 5e-25\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=step_size)\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "losslist=[]\n",
    "rmean=[]\n",
    "for i in range(50):\n",
    "    grad,lossvalue=gradient(model,loss)\n",
    "\n",
    "    new_xpos = model.xpos - step_size*grad[2]\n",
    "    new_ypos = model.xpos - step_size*grad[3] \n",
    "\n",
    "    new_grad, test_dist, test_dist_bool = constrain_distances(model, new_xpos, new_ypos, grad) # apply constraint \n",
    "    #print(new_grad)\n",
    "    #grad[1] = grad[1] * 100000\n",
    "    grad[2]=grad[2]*new_grad[0,:]\n",
    "    grad[3]=grad[3]*new_grad[1,:]\n",
    "    #grad[2] = grad[2]*new_grad[0,:]*1000\n",
    "    #grad[3] = grad[3]*new_grad[1,:]*1000   # update the gradient\n",
    "#    grad[1] = grad[1]*\n",
    "    \n",
    "    grads=remove_nan_gradients(grad)\n",
    "    #print(grads)\n",
    "    optimizer.apply_gradients(zip(grads,model.variables),global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "    T,aper=make_lenslet_tf(model)\n",
    "\n",
    "    losslist.append(lossvalue)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.cla()\n",
    "    #plt.plot(model.xpos.numpy(),model.ypos.numpy(),'o')\n",
    "    #plt.axis('equal')\n",
    "    #rmean.append(tf.reduce_mean(model.rlist.numpy()))\n",
    "    #plt.plot(rmean)\n",
    "    plt.imshow(T.numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.cla()\n",
    "    plt.plot(losslist)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf.reshape(model(0),(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Rmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T,aper=make_lenslet_tf(model)\n",
    "test2 = model.gen_psf_stack(T, aper, 0.5)\n",
    "test = model.gen_stack_spectrum(test2)\n",
    "fig = plt.figure()\n",
    "\n",
    "f,ax = plt.subplots(1,2,figsize=(20,20))\n",
    "\n",
    "ax[0].imshow(T)\n",
    "\n",
    "\n",
    "for z in range(model.Nz):\n",
    "    #ax[1].imshow((tf.real((test[z] * tf.conj(test[z])))) - model.target_F, vmax = 50)\n",
    "    ax[1].imshow((tf.real((test2[z]))),vmax = .01)\n",
    "\n",
    "    display.display(f)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(tf.reshape(model(0), (model.Nz, model.Nz)))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,aper=make_lenslet_tf(model)\n",
    "test2 = model.gen_psf_stack(T, aper, .5)\n",
    "test = model.gen_stack_spectrum(test2)\n",
    "fig = plt.figure()\n",
    "\n",
    "f,ax = plt.subplots(1,3,figsize=(20,20))\n",
    "\n",
    "ax[0].imshow(T)\n",
    "\n",
    "\n",
    "for z in range(model.Nz):\n",
    "    ax[1].imshow(tf_fftshift(tf.abs((test[z] * tf.conj(test[z])))), vmin = 0, vmax = 50)\n",
    "    ax[2].imshow(tf_fftshift(tf.abs((test[z] * tf.conj(test[z]))) - model.target_F), vmin = -50, vmax = 50)\n",
    "    #ax[1].imshow((tf.real((test[z] * tf.conj(test[z])))), vmax = 50)\n",
    "    #ax[1].imshow((tf.real((test2[z]))))\n",
    "\n",
    "    display.display(f)\n",
    "    display.clear_output(wait=True)\n",
    "    plt.pause(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian=[]\n",
    "for i in range (model.Nz**2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #tape.watch(model.variables)\n",
    "        R=model(0)\n",
    "        jacobian.append(tape.gradient(R[i], model.variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,aper=make_lenslet_tf(model)\n",
    "R=model(0)\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(T.numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tf.reshape(R,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zstack = []\n",
    "for defocus in model.defocus_list:\n",
    "    zstack.append(gen_psf_ag_tf(T,model,defocus,'angle',0., prop_pad = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R =model(0)\n",
    "\n",
    "plt.imshow(tf.reshape(R,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(zstack[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=model(0)\n",
    "plt.imshow(tf.reshape(R,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model()\n",
    "Rmat2=model2(0)\n",
    "plt.imshow(tf.reshape(Rmat2,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch((model.xpos,model.ypos))\n",
    "        Rmat=model(0) \n",
    "    for z in range(model.Nz**2)\n",
    "    der = t.gradient(Rmat,(model.xpos,model.ypos))\n",
    "#    dery = t.gradient(Rmat,model.ypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        model = Model()\n",
    "        with tf.GradientTape() as t:\n",
    "            t.watch(model.xpos)\n",
    "            Rmat=model(0) \n",
    "        derx = t.gradient(Rmat,model.xpos)\n",
    "        dery = t.gradient(Rmat,model.ypos)\n",
    "\n",
    "    \n",
    "    theta=theta+(J_f'*J_f)^(-1)*J_f'*residual;\n",
    "    i\n",
    "    sum(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rmat = np.zeros((model.Nz,model.Nz))\n",
    "start = time.time()\n",
    "Rmat_tf=[]\n",
    "psf_pad=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_pad.append(pad_frac_tf(zstack[z1],1)) #how much to pad? \n",
    "    \n",
    "psf_spect=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_spect.append(tf.fft2d(tf.complex(psf_pad[z1],tf.constant(0.,dtype = tf.float32))))\n",
    "\n",
    "normsize=tf.to_float(tf.shape(psf_spect)[0]*tf.shape(psf_spect)[1])\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    for z2 in range( model.Nz): \n",
    "        Fcorr = tf.conj(psf_spect[z1])*psf_spect[z2]\n",
    "        Rmat_tf.append(tf.reduce_sum(tf.abs(Fcorr)**2)/normsize)\n",
    "\n",
    "Rmat=tf.reshape(Rmat_tf,(7,7))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Rmat = np.zeros((model.Nz,model.Nz))\n",
    "#Rmat_tf=[]\n",
    "psf_pad=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_pad.append(pad_frac_tf(zstack[z1],1)) #how much to pad? \n",
    "    \n",
    "psf_spect=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_spect.append(tf.fft2d(tf.complex(psf_pad[z1],tf.constant(0.,dtype = tf.float32))))\n",
    "\n",
    "normsize=tf.to_float(tf.shape(psf_spect)[0]*tf.shape(psf_spect)[1])\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    for z2 in range( model.Nz): \n",
    "        Fcorr = tf.conj(psf_spect[z1])*psf_spect[z2]\n",
    "        #Rmat_tf.append(tf.reduce_sum(tf.abs(Fcorr)**2)/normsize)\n",
    "        Rmat[z1,z2] = tf.reduce_sum(tf.abs(Fcorr)**2)/normsize\n",
    "\n",
    "Rmat = tf.transpose(Rmat)*(Rmat==0) + Rmat \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1 = np.fft.fftfreq(30*30, d=1./30).reshape(30, 30)\n",
    "freqs2 = np.fft.fftfreq(30*30, d=1./40).reshape(30, 30)\n",
    "\n",
    "freqp1=np.pad(freqs1, ((30,30),(30,30)), 'constant', constant_values=(0,0))\n",
    "freqp2=np.pad(freqs2, ((30,30),(30,30)), 'constant', constant_values=(0,0))\n",
    "\n",
    "#zstack1p= pad_frac_tf(freqs1,1) #how much to pad with?\n",
    "#zstack2p= pad_frac_tf(freqs2,1)\n",
    "\n",
    "psf_spect1 = tf.fft2d(tf.complex(freqp1,tf.constant(0.,dtype = tf.float64)))\n",
    "psf_spect2 = tf.fft2d(tf.complex(freqp2,tf.constant(0.,dtype = tf.float64)))\n",
    "\n",
    "Fcorr = tf.conj(psf_spect1)*psf_spect2\n",
    "Rmat = tf.reduce_sum(tf.abs(Fcorr)**2)/(tf.to_float(tf.shape(freqp1)[0]*tf.shape(freqp1)[1]))\n",
    "Rmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcorr=signal.correlate2d(freqs1,freqs2)\n",
    "xcorr_sum=np.sum(np.abs(xcorr)**2)\n",
    "xcorr_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fcorrinv=np.fft.ifft2(Fcorr)\n",
    "s=np.sum(np.abs(Fcorrinv)**2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_spect = np.fft.fft2(zstack[0],)\n",
    "Rmat = np.zeros((model.Nz,model.Nz))\n",
    "for z1 in range(Nz):\n",
    "    for z2 in np.r_[z1:Nz]:\n",
    "      \n",
    "        Fcorr = np.conj(psf_spect[z1])*psf_spect[z2]\n",
    "        Rmat[z1,z2] = np.sum(np.abs(Fcorr)**2)\n",
    "        \n",
    "Rmat = np.transpose(Rmat)*(Rmat==0) + Rmat\n",
    "plt.imshow(Rmat,vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)\n",
    "np.fft.fft2(freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, targets):\n",
    "    error = model(inputs) - targets\n",
    "    return tf.reduce_sum(tf.square(error))\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, [model.Rlist])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
